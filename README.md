# VieNeu-TTS

[![GitHub](https://img.shields.io/badge/GitHub-Repository-blue)](https://github.com/pnnbao97/VieNeu-TTS)
[![Hugging Face](https://img.shields.io/badge/Hugging%20Face-Model-yellow)](https://huggingface.co/pnnbao-ump/VieNeu-TTS)

<img width="899" height="615" alt="Untitled" src="https://github.com/user-attachments/assets/7eb9b816-6ab7-4049-866f-f85e36cb9c6f" />

**VieNeu-TTS** is an advanced on-device Vietnamese Text-to-Speech (TTS) model with **instant voice cloning**.  

Trained on ~1000 hours of high-quality Vietnamese speech, this model represents a significant upgrade from VieNeu-TTS-140h with the following improvements:

- **Enhanced pronunciation**: More accurate and stable Vietnamese pronunciation
- **Code-switching support**: Seamless transitions between Vietnamese and English
- **Better voice cloning**: Higher fidelity and speaker consistency
- **Real-time synthesis**: 24 kHz waveform generation on CPU or GPU
- **Multiple model formats**: Support for PyTorch, GGUF Q4/Q8 (CPU optimized), and ONNX codec

VieNeu-TTS-1000h delivers production-ready speech synthesis fully offline.

**Author:** Pháº¡m Nguyá»…n Ngá»c Báº£o

[<img width="600" height="595" alt="VieNeu-TTS" src="https://github.com/user-attachments/assets/6b32df9d-7e2e-474f-94c8-43d6fa586d15" />](https://github.com/user-attachments/assets/6b32df9d-7e2e-474f-94c8-43d6fa586d15)

---

## ğŸ”¬ Model Overview

- **Backbone:** Qwen 0.5B LLM (chat template)
- **Audio codec:** NeuCodec (torch implementation; ONNX & quantized variants supported)
- **Context window:** 2 048 tokens shared by prompt text and speech tokens
- **Output watermark:** Enabled by default
- **Training data:**  
  - [VieNeu-TTS-1000h](https://huggingface.co/datasets/pnnbao-ump/VieNeu-TTS-1000h) â€” 443,641 curated Vietnamese samples  

### Model Variants

| Model | Format | Device | Quality | Speed | Streaming | RAM Usage |
|-------|--------|--------|---------|-------|-----------|-----------|
| VieNeu-TTS | PyTorch | GPU/CPU | â­â­â­â­â­ | Medium | âŒ | ~2GB |
| VieNeu-TTS-q8-gguf | GGUF Q8 | CPU/GPU | â­â­â­â­ | Fast | âœ… | ~1.5GB |
| VieNeu-TTS-q4-gguf | GGUF Q4 | CPU/GPU | â­â­â­ | Very Fast | âœ… | ~1GB |

**Recommendations:**
- **GPU users**: Use `VieNeu-TTS` (PyTorch) for best quality
- **CPU users**: Use `VieNeu-TTS-q4-gguf` for fastest inference or `VieNeu-TTS-q8-gguf` for better quality
- **Streaming**: Only GGUF models support streaming inference

---

## ğŸ Getting Started

> **ğŸ“º HÆ°á»›ng dáº«n cÃ i Ä‘áº·t báº±ng tiáº¿ng Viá»‡t**: Xem video chi tiáº¿t táº¡i [Facebook Reel](https://www.facebook.com/reel/1362972618623766)  

### 1. Clone the repository

```bash
git clone https://github.com/pnnbao97/VieNeu-TTS.git
cd VieNeu-TTS
```

### 2. Install eSpeak NG (required by phonemizer)

Follow the [official installation guide](https://github.com/espeak-ng/espeak-ng/blob/master/docs/guide.md). Common commands:

```bash
# macOS
brew install espeak

# Ubuntu / Debian
sudo apt install espeak-ng

# Arch Linux
paru -S aur/espeak-ng

# Windows
# Download installer from https://github.com/espeak-ng/espeak-ng/releases
# Default path: C:\Program Files\eSpeak NG\
# VieNeu-TTS auto-detects this path.
```

**macOS tips**
- If the phonemizer cannot find the library, set `PHONEMIZER_ESPEAK_LIBRARY` to the `.dylib` path.
- Validate installation with: `echo 'test' | espeak-ng -x -q --ipa -v vi`

### 3. Install Python dependencies (Python â‰¥ 3.12)

```bash
uv sync
```

**Note:** If you plan to use GGUF models with GPU acceleration, you may need to install `llama-cpp-python` with CUDA support:

```bash
# For CUDA support (optional, only if you have NVIDIA GPU)
CMAKE_ARGS="-DLLAMA_CUBLAS=on" pip install llama-cpp-python --force-reinstall --no-cache-dir
```

---

## ğŸ“¦ Project Structure

```
VieNeu-TTS/
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ infer_long_text.py     # CLI for long-form synthesis (chunked)
â”‚   â””â”€â”€ sample_long_text.txt   # Example paragraph for testing
â”œâ”€â”€ gradio_app.py              # Local Gradio web demo
â”œâ”€â”€ main.py                    # Basic batch inference script
â”œâ”€â”€ config.yaml                # Configuration for models and voices
â”œâ”€â”€ output_audio/              # Generated audio (created when running scripts)
â”œâ”€â”€ sample/                    # Reference voices (audio + transcript + codes)
â”‚   â”œâ”€â”€ BÃ¬nh (nam miá»n Báº¯c).wav/txt/pt
â”‚   â”œâ”€â”€ Äoan (ná»¯ miá»n Nam).wav/txt/pt
â”‚   â”œâ”€â”€ Dung (ná»¯ miá»n Nam).wav/txt/pt
â”‚   â”œâ”€â”€ HÆ°Æ¡ng (ná»¯ miá»n Báº¯c).wav/txt/pt
â”‚   â”œâ”€â”€ Ly (ná»¯ miá»n Báº¯c).wav/txt/pt
â”‚   â”œâ”€â”€ Ngá»c (ná»¯ miá»n Báº¯c).wav/txt/pt
â”‚   â”œâ”€â”€ NguyÃªn (nam miá»n Nam).wav/txt/pt
â”‚   â”œâ”€â”€ SÆ¡n (nam miá»n Nam).wav/txt/pt
â”‚   â”œâ”€â”€ TuyÃªn (nam miá»n Báº¯c).wav/txt/pt
â”‚   â””â”€â”€ VÄ©nh (nam miá»n Nam).wav/txt/pt
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core_utils.py          # Utility functions
â”‚   â”œâ”€â”€ normalize_text.py      # Vietnamese text normalization pipeline
â”‚   â”œâ”€â”€ phonemize_text.py      # Text to phoneme conversion
â”‚   â””â”€â”€ phoneme_dict.json      # Phoneme dictionary
â”œâ”€â”€ vieneu_tts/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ vieneu_tts.py          # Core VieNeuTTS implementation
â”œâ”€â”€ web_ui/                    # React-based web UI (optional)
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ pyproject.toml
```

---

## ğŸš€ Quickstart

### Gradio web demo

```bash
uv run gradio_app.py
```

Then open `http://127.0.0.1:7860` to:

- Choose from multiple model variants (PyTorch, GGUF Q4/Q8)
- Pick one of ten reference voices (5 male, 5 female; North and South accents)
- Upload your own reference audio + transcript
- Enter text up to 3000 characters (with chunking support)
- Preview or download the synthesized audio

### Basic Python usage

```python
from vieneu_tts import VieNeuTTS
import soundfile as sf

# Initialize with GGUF Q4 model for CPU
tts = VieNeuTTS(
    backbone_repo="pnnbao-ump/VieNeu-TTS-q4-gguf",
    backbone_device="cpu",
    codec_repo="neuphonic/neucodec-onnx-decoder",
    codec_device="cpu"
)

# Load reference (using pre-encoded codes for ONNX codec)
import torch
ref_codes = torch.load("./sample/VÄ©nh (nam miá»n Nam).pt", map_location="cpu")
with open("./sample/VÄ©nh (nam miá»n Nam).txt", "r", encoding="utf-8") as f:
    ref_text = f.read()

# Generate speech
text = "Xin chÃ o, Ä‘Ã¢y lÃ  má»™t vÃ­ dá»¥ vá» tá»•ng há»£p giá»ng nÃ³i tiáº¿ng Viá»‡t."
wav = tts.infer(text, ref_codes, ref_text)

# Save audio
sf.write("output.wav", wav, 24000)
```

---

## ğŸ’» Sá»­ dá»¥ng GGUF Q4 vÃ  Q8 cho CPU

GGUF models Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a Ä‘áº·c biá»‡t cho CPU, giÃºp cháº¡y nhanh hÆ¡n vÃ  tiáº¿t kiá»‡m bá»™ nhá»› so vá»›i model PyTorch gá»‘c.

### CÃ¡ch 1: Sá»­ dá»¥ng qua Gradio Web UI

1. **Khá»Ÿi Ä‘á»™ng Gradio app:**
   ```bash
   uv run gradio_app.py
   ```

2. **Chá»n model trong giao diá»‡n:**
   - **Backbone**: Chá»n `VieNeu-TTS-q4-gguf` (nhanh nháº¥t) hoáº·c `VieNeu-TTS-q8-gguf` (cháº¥t lÆ°á»£ng tá»‘t hÆ¡n)
   - **Codec**: Chá»n `NeuCodec ONNX (Fast CPU)` Ä‘á»ƒ tá»‘i Æ°u tá»‘c Ä‘á»™ trÃªn CPU
   - **Device**: Chá»n `CPU`

3. **Click "ğŸ”„ Táº£i Model"** vÃ  Ä‘á»£i model táº£i vá» (láº§n Ä‘áº§u sáº½ máº¥t thá»i gian)

4. **Sá»­ dá»¥ng nhÆ° bÃ¬nh thÆ°á»ng** - model sáº½ tá»± Ä‘á»™ng cháº¡y trÃªn CPU

### CÃ¡ch 2: Sá»­ dá»¥ng qua Python code

#### Sá»­ dá»¥ng GGUF Q4 (nháº¹ nháº¥t, nhanh nháº¥t)

```python
from vieneu_tts import VieNeuTTS
import soundfile as sf
import torch

# Khá»Ÿi táº¡o model Q4 cho CPU
tts = VieNeuTTS(
    backbone_repo="pnnbao-ump/VieNeu-TTS-q4-gguf",
    backbone_device="cpu",  # Sá»­ dá»¥ng CPU
    codec_repo="neuphonic/neucodec-onnx-decoder",  # ONNX codec cho CPU
    codec_device="cpu"
)

# Load reference codes (pre-encoded cho ONNX codec)
ref_codes = torch.load("./sample/VÄ©nh (nam miá»n Nam).pt", map_location="cpu")
with open("./sample/VÄ©nh (nam miá»n Nam).txt", "r", encoding="utf-8") as f:
    ref_text = f.read()

# Tá»•ng há»£p giá»ng nÃ³i
text = "ÄÃ¢y lÃ  vÃ­ dá»¥ sá»­ dá»¥ng model Q4 trÃªn CPU."
wav = tts.infer(text, ref_codes, ref_text)

# LÆ°u file audio
sf.write("output_q4.wav", wav, 24000)
print("âœ… ÄÃ£ táº¡o file output_q4.wav")
```

#### Sá»­ dá»¥ng GGUF Q8 (cháº¥t lÆ°á»£ng tá»‘t hÆ¡n)

```python
from vieneu_tts import VieNeuTTS
import soundfile as sf
import torch

# Khá»Ÿi táº¡o model Q8 cho CPU
tts = VieNeuTTS(
    backbone_repo="pnnbao-ump/VieNeu-TTS-q8-gguf",
    backbone_device="cpu",
    codec_repo="neuphonic/neucodec-onnx-decoder",
    codec_device="cpu"
)

# Load reference
ref_codes = torch.load("./sample/VÄ©nh (nam miá»n Nam).pt", map_location="cpu")
with open("./sample/VÄ©nh (nam miá»n Nam).txt", "r", encoding="utf-8") as f:
    ref_text = f.read()

# Tá»•ng há»£p
text = "ÄÃ¢y lÃ  vÃ­ dá»¥ sá»­ dá»¥ng model Q8 trÃªn CPU vá»›i cháº¥t lÆ°á»£ng tá»‘t hÆ¡n."
wav = tts.infer(text, ref_codes, ref_text)

sf.write("output_q8.wav", wav, 24000)
print("âœ… ÄÃ£ táº¡o file output_q8.wav")
```

### Streaming vá»›i GGUF models

GGUF models há»— trá»£ streaming inference, cho phÃ©p nghe audio trong khi Ä‘ang táº¡o. 

### LÆ°u Ã½ quan trá»ng khi sá»­ dá»¥ng GGUF trÃªn CPU

1. **Pre-encoded codes**: Khi sá»­ dá»¥ng `neuphonic/neucodec-onnx-decoder`, báº¡n cáº§n sá»­ dá»¥ng file `.pt` (pre-encoded codes) thay vÃ¬ encode tá»« audio. CÃ¡c file `.pt` Ä‘Ã£ cÃ³ sáºµn trong thÆ° má»¥c `sample/`.

2. **Náº¿u khÃ´ng cÃ³ file .pt**: Báº¡n cÃ³ thá»ƒ encode tá»« audio báº±ng cÃ¡ch sá»­ dá»¥ng codec PyTorch trÆ°á»›c:
   ```python
   # Táº¡m thá»i dÃ¹ng PyTorch codec Ä‘á»ƒ encode
   tts_temp = VieNeuTTS(
       backbone_repo="pnnbao-ump/VieNeu-TTS-q4-gguf",
       backbone_device="cpu",
       codec_repo="neuphonic/neucodec",  # PyTorch codec
       codec_device="cpu"
   )
   ref_codes = tts_temp.encode_reference("./sample/VÄ©nh (nam miá»n Nam).wav")
   torch.save(ref_codes, "./sample/VÄ©nh (nam miá»n Nam).pt")
   ```

3. **Tá»‘i Æ°u hiá»‡u nÄƒng CPU**:
   - Sá»­ dá»¥ng Q4 cho tá»‘c Ä‘á»™ tá»‘i Ä‘a
   - Sá»­ dá»¥ng ONNX codec cho codec decoding nhanh hÆ¡n
   - Giáº£m `max_chars_per_chunk` náº¿u gáº·p váº¥n Ä‘á» vá» bá»™ nhá»›

4. **GPU acceleration (tÃ¹y chá»n)**: Náº¿u cÃ³ NVIDIA GPU vÃ  Ä‘Ã£ cÃ i `llama-cpp-python` vá»›i CUDA, báº¡n cÃ³ thá»ƒ dÃ¹ng `backbone_device="gpu"` Ä‘á»ƒ tÄƒng tá»‘c.

---

## ğŸ”ˆ Reference Voices (`sample/`)

| File                    | Gender | Accent | Description        |
|-------------------------|--------|--------|--------------------|
| BÃ¬nh (nam miá»n Báº¯c)     | Male   | North  | Male voice, North accent |
| TuyÃªn (nam miá»n Báº¯c)    | Male   | North  | Male voice, North accent |
| NguyÃªn (nam miá»n Nam)   | Male   | South  | Male voice, South accent |
| SÆ¡n (nam miá»n Nam)      | Male   | South  | Male voice, South accent |
| VÄ©nh (nam miá»n Nam)     | Male   | South  | Male voice, South accent |
| HÆ°Æ¡ng (ná»¯ miá»n Báº¯c)     | Female | North  | Female voice, North accent |
| Ly (ná»¯ miá»n Báº¯c)        | Female | North  | Female voice, North accent |
| Ngá»c (ná»¯ miá»n Báº¯c)      | Female | North  | Female voice, North accent |
| Äoan (ná»¯ miá»n Nam)      | Female | South  | Female voice, South accent |
| Dung (ná»¯ miá»n Nam)      | Female | South  | Female voice, South accent |

Each reference voice includes:
- `.wav` - Audio file
- `.txt` - Transcript file
- `.pt` - Pre-encoded codes (for ONNX codec)

**Note:** GGUF models hiá»‡n táº¡i chá»‰ há»— trá»£ 4 giá»ng: VÄ©nh, BÃ¬nh, Ngá»c, vÃ  Dung.

---

## ğŸ“š References

- [GitHub Repository](https://github.com/pnnbao97/VieNeu-TTS)  
- [Hugging Face Model Card](https://huggingface.co/pnnbao-ump/VieNeu-TTS)  
- [NeuTTS Air base model](https://huggingface.co/neuphonic/neutts-air)  
- [Fine-tuning guide](https://github.com/pnnbao-ump/VieNeuTTS/blob/main/finetune.ipynb)  
- [VieNeuCodec dataset](https://huggingface.co/datasets/pnnbao-ump/VieNeuCodec-dataset)

---

## ğŸ“„ License

Apache License 2.0

---

## ğŸ“‘ Citation

```bibtex
@misc{vieneutts2025,
  title        = {VieNeu-TTS: Vietnamese Text-to-Speech with Instant Voice Cloning},
  author       = {Pham Nguyen Ngoc Bao},
  year         = {2025},
  publisher    = {Hugging Face},
  howpublished = {\url{https://huggingface.co/pnnbao-ump/VieNeu-TTS}}
}
```

Please also cite the base model:

```bibtex
@misc{neuttsair2025,
  title        = {NeuTTS Air: On-Device Speech Language Model with Instant Voice Cloning},
  author       = {Neuphonic},
  year         = {2025},
  publisher    = {Hugging Face},
  howpublished = {\url{https://huggingface.co/neuphonic/neutts-air}}
}
```

---

## ğŸ¤ Contributing

Contributions are welcome!

1. Fork the repository  
2. Create a feature branch: `git checkout -b feature/amazing-feature`  
3. Commit your changes: `git commit -m "Add amazing feature"`  
4. Push the branch: `git push origin feature/amazing-feature`  
5. Open a pull request

---

## ğŸ“ Support

- GitHub Issues: [github.com/pnnbao97/VieNeu-TTS/issues](https://github.com/pnnbao97/VieNeu-TTS/issues)  
- Hugging Face: [huggingface.co/pnnbao-ump](https://huggingface.co/pnnbao-ump)  
- Facebook: [Pháº¡m Nguyá»…n Ngá»c Báº£o](https://www.facebook.com/bao.phamnguyenngoc.5)

---

## ğŸ™ Acknowledgements

This project builds upon [NeuTTS Air](https://huggingface.co/neuphonic/neutts-air) by Neuphonic. Huge thanks to the team for open-sourcing such a powerful base model.

---

**Made with â¤ï¸ for the Vietnamese TTS community**
